Given a sentence $\mathcal{S} = \langle w_1, w_2 \ldots w_n \rangle$ and a span $\langle s, e\rangle$, where $s$ and $e$ are the start and end indices, the goal of this module is to identify a label $t \in \mathcal{T}$  for the span, where $\mathcal{T}$ is the set of all entity types.
Interestingly, we model this problem as the reverse of \method{BERT-QA}. \method{BERT-QA} takes an entity type as input question along with the sentence and returns corresponding mentions. On the contrary, our setup takes a mention span as input along with the sentence and outputs its entity type.

During training, we create an input training sample for each gold entity mention in a sentence. During inference, this module gets the mention outputs from \spandetect{} as its input. For a given sentence and mention, we suffix the question \textit{``What is [mention]?"}, where \textit{[mention]} is the string corresponding to the mention span in the sentence. The samples are fed to a BERT model which does sequence classification. The pooled sequence embedding returned by BERT is fed to a fully connected layer and converted into a probability distribution over the entity types. Figure \ref{fig:framework} explains this setup with an example.

% Note that, each input sentence is multiplied by the number of entity mentions in the sentence in our method, while, in the MRC system, all the input sentences are multiplied by the number of entity types resulting in a huge increase of training data when the number of target entity types is large.

Most real world datasets do not have a similar distribution among entity types. %Some entities are very common while others are rare. 
This leads to a class imbalance and may bias the model to classify entity mentions into the more common entity types. A recent study \cite{li2019dice} has shown that using dice coefficient as the loss function is more beneficial than cross entropy loss in such situations. Inspired by this work, we trained the \spanclass{} using dice loss. Experiments and ablations later show its effectiveness compared to cross entropy loss. 

% \comment{may also say that dice loss is less effective in general NER setup (as shown by our NER experiments) and more effective when specially done for span classification}
