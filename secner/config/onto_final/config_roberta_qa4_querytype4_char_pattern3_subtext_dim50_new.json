{
  "model_name": "ner-roberta-qa4-querytype4-char-pattern3-subtext-dim50-new",
  "dataset_dir": "onto_final",
  "num_labels": 4,
  "do_train": true,
  "resume": null,
  "num_train_epochs": 300,
  "data_root": "../data",
  "out_root": "../out",
  "train_path": "train.tsv",
  "dev_path": "dev.tsv",
  "test_path": "test.tsv",
  "tag_vocab_path": "tag_vocab.txt",
  "tag_names_path": "tag_names.txt",
  "pad_tag": "[PAD]",
  "none_tag": "O",
  "max_seq_len": 512,
  "token_type": "sub_text",
  "char_emb_dim": 50,
  "pattern_type": "3",
  "use_char_cnn": "both",
  "cnn_num_filters": 16,
  "cnn_kernel_size": 5,
  "cnn_dropout_rate": 0.3,
  "freeze_bert": false,
  "query_type": "question4",
  "model_mode": "roberta_std",
  "base_model": "roberta-base",
  "evaluation_strategy": "steps",
  "logging_steps": 30000,
  "save_total_limit": 2,
  "load_best_model_at_end": true,
  "metric_for_best_model": "micro_f1",
  "per_device_train_batch_size": 16,
  "per_device_eval_batch_size": 16,
  "learning_rate": 1e-4
}
